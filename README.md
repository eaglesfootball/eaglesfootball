- üëã Hi, I‚Äôm @eaglesfootball
- üëÄ I‚Äôm interested in ...
- üå± I‚Äôm currently learning ...
- üíûÔ∏è I‚Äôm looking to collaborate on ...
- üì´ How to reach me ...

<!---
eaglesfootball/eaglesfootball is a ‚ú® special ‚ú® repository because its `README.md` (this file) appears on your GitHub profile.
You can click the Preview link to take a look at your changes.
--->
import matplotlib.pyplot as plt
import numpy as np
import os
import PIL
import tensorflow as tf
import pandas as pd
 
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
 
import pathlib
 
# Import Dataset
data_dir = pathlib.Path(r"C:\Users\eagle\anaconda\Lib\massjpg2")
cancer_train = pd.read_csv(
    r"C:\Users\eagle\anaconda\Lib\training.csv",
    names=["Image", "Has"])

cancer_train.head()

cancer_features = cancer_train.copy()
cancer_labels = cancer_features.pop('Has')

print (cancer_labels)

cancer_features = np.array(cancer_features)
cancer_features
train_data_path =  r"C:\Users\eagle\anaconda\Lib\training.csv" #path where data is stored
train_data = pd.read_csv(train_data_path, header=None) #load data in dataframe using pandas
 
# Create a dataset
 
batch_size = 60
img_height = 180
img_width = 180
 
train_ds = keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.8,
  subset="training",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)
 
val_ds = keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset="validation",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)
 
# Configure the dataset for performance
 
AUTOTUNE = tf.data.AUTOTUNE
 
train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)
 
# Standardize the data
 
normalization_layer = layers.Rescaling(1./255)
 
normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))
image_batch, labels_batch = next(iter(normalized_ds))
first_image = image_batch[0]
# Notice the pixel values are now in `[0,1]`.
print(np.min(first_image), np.max(first_image))
 
# Create the model
 
num_classes = 2
 
model = Sequential([
  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),
  layers.Conv2D(16, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(32, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(64, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Flatten(),
  layers.Dense(128, activation='relu'),
  layers.Dense(num_classes)
])
 
# Compile the model
model.compile(optimizer='adam',loss='mean_squared_error')
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
             metrics=['accuracy'])

#val_set = [(sample, label),(sample, label),(sample, label)]
#model.fit(train_ds, validation_split = 0.2, batch_size = 10, epochs = 20, shuffle= True , verbose = 2) 

 
model.summary()
 
# Train the model
 
epochs=10
history = model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=epochs
)
 
# Visualize training results
 
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
 
loss = history.history['loss']
val_loss = history.history['val_loss']
 
epochs_range = range(epochs)
 
plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')
 
plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()
 
# Compile and train the model
 
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
 
model.summary()
 
epochs = 15
history = model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=epochs
)
 
# Visualize training results
 
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
 
loss = history.history['loss']
val_loss = history.history['val_loss']
 
epochs_range = range(epochs)
 
plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')
 
plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()
